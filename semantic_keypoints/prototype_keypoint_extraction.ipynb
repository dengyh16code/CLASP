{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e800cc-b4e6-4403-be5d-04c478dac4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dependencies\n",
    "\n",
    "import os \n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append(\"/home/adacomp/CLASP\")\n",
    "\n",
    "print(os.environ['OPENAI_API_KEY']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c929e2-d4b9-4eb9-bfc9-5e3f118d59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process import resize\n",
    "\n",
    "img_size = 480\n",
    "image_path = \"/home/adacomp/CLASP/object_template/dress_1.png\"\n",
    "obs_image= resize(Image.open(image_path).convert('RGB'), target_res=img_size, resize=True, to_pil=True)\n",
    "\n",
    "background_image_path = \"/home/adacomp/CLASP/semantic_keypoints/prototype/background.png\"\n",
    "background = resize(Image.open(background_image_path).convert('RGB'), target_res=img_size, resize=True, to_pil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloud_services.apis.owlv2 import OWLViT\n",
    "from cloud_services.apis.sam import SAM,visualize_image\n",
    "\n",
    "detector = OWLViT()\n",
    "sam = SAM()        \n",
    "\n",
    "detected_objects = detector.detect_objects(\n",
    "        image=obs_image,\n",
    "        text_queries= ['dress','cloth', 'clothes', 'trousers', 'skirt', 'tshirt', 'towel', 'traiangle'],   #'white object'], #['cloth', 'trousers', 'skirt', 'tshirt', ],\n",
    "        bbox_score_top_k=25,\n",
    "        bbox_conf_threshold=0.10)\n",
    "\n",
    "best_score = 0\n",
    "best_boxes = None\n",
    "for det in detected_objects:\n",
    "    if det[\"score\"] > best_score:\n",
    "        best_score = det[\"score\"]\n",
    "        best_boxes = det['bbox']\n",
    "if best_boxes is None:\n",
    "    print(\"No clothes detected\")\n",
    "    exit(0)\n",
    "    \n",
    "        # print(best_boxes)\n",
    "# visualize_image(obs_image, bboxes=[best_boxes], show=True, return_img=True)\n",
    "masks = sam.segment_by_bboxes(image=obs_image, bboxes=[best_boxes])\n",
    "print(np.array(masks[0][\"segmentation\"]).astype(np.uint8))\n",
    "print(np.array(masks[0][\"segmentation\"].shape))\n",
    "np.save(\"/home/adacomp/CLASP/object_template/dress_1.npy\", np.array(masks[0][\"segmentation\"]).astype(np.uint8))\n",
    "visualize_image(obs_image, masks=[mask[\"segmentation\"] for mask in masks], show=True, return_img=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc799258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process import center_object\n",
    "img_processed, mask_processed, _ = center_object(np.array(obs_image), np.array(masks[0][\"segmentation\"]), background, size_ratio=1.2)\n",
    "plt.imshow(img_processed)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "visualize_image(img_processed, masks=[mask_processed], show=True, return_img=False) \n",
    "print(\"center process\")\n",
    "obs_processed = Image.fromarray(img_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from skimage.morphology import medial_axis\n",
    "from skimage.filters import gaussian\n",
    "import cv2 as cv\n",
    "\n",
    "def sample_uniform_keypoints(contour, num_samples):\n",
    "    # Calculate the cumulative distances along the contour\n",
    "    contour = contour.squeeze()  # Remove redundant dimension\n",
    "    cumulative_distances = [0]\n",
    "    \n",
    "    for i in range(1, len(contour)):\n",
    "        dist = np.linalg.norm(contour[i] - contour[i - 1])\n",
    "        cumulative_distances.append(cumulative_distances[-1] + dist)\n",
    "    \n",
    "    total_length = cumulative_distances[-1]\n",
    "    step_size = total_length / (num_samples - 1)  # Uniform step size for sampling\n",
    "    print(\"step_size\", step_size)\n",
    "    \n",
    "    sampled_points = [contour[0]]  # Start with the first point\n",
    "\n",
    "    # Traverse the contour and sample points at uniform intervals\n",
    "    current_distance = step_size\n",
    "    for i in range(1, len(contour)):\n",
    "        while cumulative_distances[i] >= current_distance:\n",
    "            # Linear interpolation between two points\n",
    "            t = (current_distance - cumulative_distances[i - 1]) / (cumulative_distances[i] - cumulative_distances[i - 1])\n",
    "            sampled_point = (1 - t) * contour[i - 1] + t * contour[i]\n",
    "            sampled_points.append(sampled_point)\n",
    "            current_distance += step_size\n",
    "\n",
    "    return np.array(sampled_points, dtype=np.int32)\n",
    "\n",
    "mask = copy.deepcopy(mask_processed)\n",
    "\n",
    "#  Apply Gaussian blur (sigma controls the amount of smoothing)\n",
    "smoothed_image = gaussian(mask, sigma=1)\n",
    "\n",
    "# Threshold back to binary\n",
    "mask_cleaned = smoothed_image > 0.5\n",
    "skeleton, distance = medial_axis(mask,return_distance= True)                      \n",
    "\n",
    "# for contour in contours:\n",
    "#     for point in contour:\n",
    "#         cv.circle( self.draw_depth , tuple(point[0]), 3, (0, 0, 255), -1)  # Red keypoints\n",
    "contours, _ = cv.findContours(mask.astype(np.uint8)*255, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "contour = max(contours, key=cv.contourArea)\n",
    "contour_index = sample_uniform_keypoints(contour, num_samples=50)\n",
    "print(\"contour_shape\", contour_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba190847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.geometric_utils import detect_robust_direction_changes, remove_overlapping_keypoints, fps\n",
    "\n",
    "inflection_points = detect_robust_direction_changes(contour_index, angle_threshold=5)\n",
    "skeleton_points = np.argwhere(skeleton)\n",
    "skeleton_index = sample_uniform_keypoints(skeleton_points, num_samples=50)\n",
    "candidate_skeleton_keypoints = fps(skeleton_points, 10)\n",
    "\n",
    "all_points = np.concatenate((contour_index, fps(skeleton_points[:,::-1],40)), axis=0)\n",
    "all_points = remove_overlapping_keypoints(all_points,min_distance=20)\n",
    "candidate_keypoints = fps(all_points, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visual_prompt_utils import annotate_candidate_keypoints\n",
    "\n",
    "#annotated_image_raw = annotate_candidate_keypoints(obs_image, all_points, add_caption=False)\n",
    "\n",
    "\n",
    "annotated_image = annotate_candidate_keypoints(obs_processed, candidate_keypoints, add_caption=True)\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a535cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_utils import load_prompts\n",
    "    \n",
    "prompts = load_prompts()\n",
    "prompt_kp = prompts['semantic_kp']\n",
    "print(prompt_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaa432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_utils import request_gpt\n",
    "\n",
    "res = request_gpt(\"\",[annotated_image],prompt_kp)\n",
    "print(res)\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
